{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique token for this session \n",
    "SESSION_TOKEN = 'example'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from graphviz import Digraph\n",
    "from consensus_simple.train_consensus import main, get_train_loaders\n",
    "from resnet import resnet20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your paths for loading dataset and stats saving\n",
    "BASE_DIR = Path().cwd()\n",
    "\n",
    "SAVE_DIR = BASE_DIR.joinpath('stat_dir').joinpath(SESSION_TOKEN)\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATASET_NAME = 'cifar10'\n",
    "DATASET_DIR = BASE_DIR.parent / 'distributed-learning' / 'data' / DATASET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: topology Pages: 1 -->\n",
       "<svg width=\"272pt\" height=\"204pt\"\n",
       " viewBox=\"0.00 0.00 272.43 204.43\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 200.43)\">\n",
       "<title>topology</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-200.43 268.43,-200.43 268.43,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"red\" cx=\"107.21\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.21\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M132.66,-24.69C143.24,-25.15 152.21,-22.92 152.21,-18 152.21,-14.77 148.35,-12.7 142.7,-11.79\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"142.81,-8.29 132.66,-11.31 142.48,-15.28 142.81,-8.29\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.21\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">0.34</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"red\" cx=\"27\" cy=\"-98.21\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-94.51\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M87.06,-30.31C73.57,-41.77 56.14,-58.98 43.47,-73.27\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"40.47,-71.39 36.63,-81.27 45.79,-75.94 40.47,-71.39\"/>\n",
       "<text text-anchor=\"middle\" x=\"49.27\" y=\"-55.59\" font-family=\"Times,serif\" font-size=\"14.00\">0.33</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"red\" cx=\"187.43\" cy=\"-98.21\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"187.43\" y=\"-94.51\" font-family=\"Times,serif\" font-size=\"14.00\">3</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;3 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>0&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M116.81,-34.9C127.44,-47.91 144.78,-65.74 159.67,-79.22\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"157.36,-81.85 167.18,-85.83 161.98,-76.59 157.36,-81.85\"/>\n",
       "<text text-anchor=\"middle\" x=\"122.24\" y=\"-60.86\" font-family=\"Times,serif\" font-size=\"14.00\">0.33</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;0 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M47.16,-85.91C60.65,-74.45 78.07,-57.23 90.74,-42.95\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"93.75,-44.82 97.58,-34.95 88.42,-40.27 93.75,-44.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"84.95\" y=\"-68.23\" font-family=\"Times,serif\" font-size=\"14.00\">0.33</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M52.44,-104.9C63.03,-105.37 72,-103.14 72,-98.21 72,-94.98 68.14,-92.91 62.49,-92\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"62.6,-88.5 52.44,-91.52 62.27,-95.5 62.6,-88.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"88\" y=\"-94.51\" font-family=\"Times,serif\" font-size=\"14.00\">0.34</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"red\" cx=\"107.21\" cy=\"-178.43\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.21\" y=\"-174.73\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M36.59,-115.11C47.23,-128.12 64.57,-145.95 79.46,-159.44\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"77.15,-162.07 86.97,-166.04 81.77,-156.81 77.15,-162.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"42.02\" y=\"-141.07\" font-family=\"Times,serif\" font-size=\"14.00\">0.33</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>3&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M177.84,-81.32C167.2,-68.31 149.86,-50.48 134.97,-36.99\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"137.28,-34.36 127.46,-30.39 132.66,-39.62 137.28,-34.36\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.4\" y=\"-62.95\" font-family=\"Times,serif\" font-size=\"14.00\">0.33</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;3 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>3&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M212.87,-104.9C223.46,-105.37 232.43,-103.14 232.43,-98.21 232.43,-94.98 228.56,-92.91 222.92,-92\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"223.03,-88.5 212.87,-91.52 222.69,-95.5 223.03,-88.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.43\" y=\"-94.51\" font-family=\"Times,serif\" font-size=\"14.00\">0.34</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;2 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>3&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M167.27,-110.52C153.78,-121.98 136.36,-139.2 123.69,-153.48\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"120.68,-151.61 116.84,-161.48 126,-156.16 120.68,-151.61\"/>\n",
       "<text text-anchor=\"middle\" x=\"129.48\" y=\"-135.8\" font-family=\"Times,serif\" font-size=\"14.00\">0.33</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M97.62,-161.53C86.99,-148.52 69.64,-130.69 54.76,-117.21\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"57.07,-114.58 47.25,-110.6 52.44,-119.83 57.07,-114.58\"/>\n",
       "<text text-anchor=\"middle\" x=\"92.19\" y=\"-143.17\" font-family=\"Times,serif\" font-size=\"14.00\">0.33</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M127.37,-166.12C140.86,-154.66 158.29,-137.44 170.95,-123.16\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"173.96,-125.03 177.8,-115.16 168.64,-120.49 173.96,-125.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"165.16\" y=\"-148.44\" font-family=\"Times,serif\" font-size=\"14.00\">0.33</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;2 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>2&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M132.66,-185.12C143.24,-185.58 152.21,-183.35 152.21,-178.43 152.21,-175.2 148.35,-173.13 142.7,-172.22\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"142.81,-168.72 132.66,-171.74 142.48,-175.71 142.81,-168.72\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.21\" y=\"-174.73\" font-family=\"Times,serif\" font-size=\"14.00\">0.34</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f93c3255cd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_agents = 4\n",
    "\n",
    "topology = {\n",
    "    0: {0: 0.34, \n",
    "        1: 0.33,\n",
    "        3: 0.33,\n",
    "       },\n",
    "    1: {1: 0.34, \n",
    "        0: 0.33,\n",
    "        2: 0.33,\n",
    "       },\n",
    "    2: {2: 0.34, \n",
    "        1: 0.33,\n",
    "        3: 0.33,\n",
    "       },\n",
    "    3: {3: 0.34, \n",
    "        2: 0.33,\n",
    "        0: 0.33,\n",
    "       },\n",
    "}\n",
    "\n",
    "g = Digraph(name='topology', directory=SAVE_DIR, engine='circo')\n",
    "g.attr('node', color='red')\n",
    "g.attr('edge', color='blue')\n",
    "g.attr(size='8,5')\n",
    "\n",
    "for agent, neighbors in topology.items():\n",
    "    g.node(str(agent))\n",
    "    for neighbor, w in neighbors.items():\n",
    "        g.edge(str(neighbor), str(agent), label=\"{:.02f}\".format(w))\n",
    "g.save()\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(log_file_path='logs.log'):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    fh = logging.FileHandler(log_file_path)\n",
    "    fh.setLevel(logging.INFO)\n",
    "\n",
    "    ch = logging.StreamHandler()\n",
    "    #ch.setLevel(logging.DEBUG)\n",
    "    ch.setLevel(logging.INFO)\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fh.setFormatter(formatter)\n",
    "    ch.setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(fh)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {agent_name: int(50000/len(topology)) for agent_name in topology}\n",
    "print(sum(dataset_sizes.values()))\n",
    "\n",
    "train_freqs = {agent_name: 1 for agent_name in topology}\n",
    "consensus_freqs = train_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Info about future train loaders:\n",
      "For 0 agent 391 batches\n",
      "For 1 agent 391 batches\n",
      "For 2 agent 391 batches\n",
      "For 3 agent 391 batches\n",
      "\n",
      "Epoch size = 391 batches\n"
     ]
    }
   ],
   "source": [
    "_train_loaders = get_train_loaders({\n",
    "    'dataset_dir': DATASET_DIR,\n",
    "    'dataset_sizes': dataset_sizes,\n",
    "    'train_batch_size': train_batch_size,\n",
    "    'dataset_name': DATASET_NAME,\n",
    "})\n",
    "\n",
    "epoch_size = 0\n",
    "\n",
    "print('Info about future train loaders:')\n",
    "for agent_name, loader in _train_loaders.items():\n",
    "    epoch_size = max(epoch_size, len(loader))\n",
    "    print('For {} agent {} batches'.format(agent_name, len(loader)))\n",
    "\n",
    "print('\\nEpoch size = {} batches'.format(epoch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(iteration):\n",
    "    factor = args['n_agents'] if args['use_lsr'] else 1.0\n",
    "    if iteration < epoch_size*5:  # gradual warmup\n",
    "        factor = factor*iteration/(epoch_size*5)\n",
    "    if iteration >= epoch_size*81:\n",
    "        factor /= 10\n",
    "    if iteration >= epoch_size*122:\n",
    "        factor /= 10\n",
    "    return factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'dataset_name': DATASET_NAME,\n",
    "    'dataset_dir': DATASET_DIR,\n",
    "    \n",
    "    # путь до папки куда сохраняется статистика\n",
    "    'save_path': SAVE_DIR,\n",
    "\n",
    "    'train_batch_size': train_batch_size,\n",
    "    'test_batch_size': 128,\n",
    "\n",
    "    'lr': 0.1,\n",
    "    'momentum': 0.9,\n",
    "    'weight_decay': 1e-4,\n",
    "    'lr_schedule': lr_schedule,\n",
    "    \n",
    "    'topology': topology,\n",
    "    'n_agents': len(topology),\n",
    "    \n",
    "    # True, если хотим перед обучением параметры всех агентов сделать идентичными \n",
    "    'equalize_start_params': True,\n",
    "\n",
    "    # True если хотим learning_rate умножить на количество агентов в сети\n",
    "    'use_lsr': True,\n",
    "    \n",
    "    # Задает количество итераций.\n",
    "    # Если <= 200, то считается количеством эпох\n",
    "    # и в этом случае умножается на размер самого большого куска датасета. \n",
    "    'num_epochs': 1,\n",
    "    \n",
    "    # Частота обучения одного батча для каждого агента. Измеряется в батчах.\n",
    "    'train_freqs': train_freqs, \n",
    "    \n",
    "    # Частота усреднения параметров для каждого агента. Измеряется в батчах.\n",
    "    # Если хочется усредняться после каждого батча, должно быть равным train_freqs\n",
    "    'consensus_freqs': consensus_freqs,\n",
    "    \n",
    "    # Частота сбора статистики. Измеряется в батчах.\n",
    "    'stat_freq': epoch_size,\n",
    "    \n",
    "    # Количество данных для каждого агента. \n",
    "    # Значения должны суммироваться к размеру датасета. Для cifar10 это 50000. \n",
    "    'dataset_sizes': dataset_sizes,\n",
    "\n",
    "    'model': resnet20,\n",
    "    \n",
    "    #'checkpoint_path': SAVE_DIR,\n",
    "}\n",
    "\n",
    "args['logger'] = get_logger(log_file_path=SAVE_DIR.joinpath('logs.log'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-03 01:19:38,158 - __main__ - INFO - START with args \n",
      "{'dataset_name': 'cifar10', 'dataset_dir': PosixPath('/home/sergey/Documents/homeworks/distrib_learning/distributed-learning/data/cifar10'), 'save_path': PosixPath('/home/sergey/Documents/homeworks/distrib_learning/pytorch_resnet_cifar10/stat_dir/example'), 'train_batch_size': 32, 'test_batch_size': 128, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0001, 'lr_schedule': <function lr_schedule at 0x7f93c3253940>, 'topology': {0: {0: 0.34, 1: 0.33, 3: 0.33}, 1: {1: 0.34, 0: 0.33, 2: 0.33}, 2: {2: 0.34, 1: 0.33, 3: 0.33}, 3: {3: 0.34, 2: 0.33, 0: 0.33}}, 'n_agents': 4, 'equalize_start_params': True, 'use_lsr': True, 'num_epochs': 1, 'train_freqs': {0: 1, 1: 1, 2: 1, 3: 1}, 'consensus_freqs': {0: 1, 1: 1, 2: 1, 3: 1}, 'stat_freq': 391, 'dataset_sizes': {0: 12500, 1: 12500, 2: 12500, 3: 12500}, 'model': <function resnet20 at 0x7f93c3246700>, 'logger': <Logger __main__ (DEBUG)>}\n",
      "2021-06-03 01:19:38,158 - __main__ - INFO - START with args \n",
      "{'dataset_name': 'cifar10', 'dataset_dir': PosixPath('/home/sergey/Documents/homeworks/distrib_learning/distributed-learning/data/cifar10'), 'save_path': PosixPath('/home/sergey/Documents/homeworks/distrib_learning/pytorch_resnet_cifar10/stat_dir/example'), 'train_batch_size': 32, 'test_batch_size': 128, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0001, 'lr_schedule': <function lr_schedule at 0x7f93c3253940>, 'topology': {0: {0: 0.34, 1: 0.33, 3: 0.33}, 1: {1: 0.34, 0: 0.33, 2: 0.33}, 2: {2: 0.34, 1: 0.33, 3: 0.33}, 3: {3: 0.34, 2: 0.33, 0: 0.33}}, 'n_agents': 4, 'equalize_start_params': True, 'use_lsr': True, 'num_epochs': 1, 'train_freqs': {0: 1, 1: 1, 2: 1, 3: 1}, 'consensus_freqs': {0: 1, 1: 1, 2: 1, 3: 1}, 'stat_freq': 391, 'dataset_sizes': {0: 12500, 1: 12500, 2: 12500, 3: 12500}, 'model': <function resnet20 at 0x7f93c3246700>, 'logger': <Logger __main__ (DEBUG)>}\n",
      "2021-06-03 01:19:38,160 - __main__ - INFO - Mixer successfully prepared\n",
      "2021-06-03 01:19:38,160 - __main__ - INFO - Mixer successfully prepared\n",
      "2021-06-03 01:19:38,161 - __main__ - INFO - StatisticCollector successfully prepared\n",
      "2021-06-03 01:19:38,161 - __main__ - INFO - StatisticCollector successfully prepared\n",
      "2021-06-03 01:19:38,552 - __main__ - INFO - Test loader with length 79 successfully prepared\n",
      "2021-06-03 01:19:38,552 - __main__ - INFO - Test loader with length 79 successfully prepared\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-03 01:19:39,715 - __main__ - INFO - Train loaders successfully prepared\n",
      "2021-06-03 01:19:39,715 - __main__ - INFO - Train loaders successfully prepared\n",
      "2021-06-03 01:19:45,593 - __main__ - INFO - 4 Models successfully prepared\n",
      "2021-06-03 01:19:45,593 - __main__ - INFO - 4 Models successfully prepared\n",
      "2021-06-03 01:19:45,594 - __main__ - INFO - Preparing took 0:00:07\n",
      "2021-06-03 01:19:45,594 - __main__ - INFO - Preparing took 0:00:07\n",
      "2021-06-03 01:19:45,698 - __main__ - INFO - Agent 0 successfully prepared\n",
      "2021-06-03 01:19:45,698 - __main__ - INFO - Agent 0 successfully prepared\n",
      "2021-06-03 01:19:45,747 - __main__ - INFO - Agent 1 successfully prepared\n",
      "2021-06-03 01:19:45,747 - __main__ - INFO - Agent 1 successfully prepared\n",
      "2021-06-03 01:19:45,786 - __main__ - INFO - Agent 2 successfully prepared\n",
      "2021-06-03 01:19:45,786 - __main__ - INFO - Agent 2 successfully prepared\n",
      "2021-06-03 01:19:45,859 - __main__ - INFO - Agent 3 successfully prepared\n",
      "2021-06-03 01:19:45,859 - __main__ - INFO - Agent 3 successfully prepared\n",
      "2021-06-03 01:19:45,870 - __main__ - INFO - Training started from 1 iteration\n",
      "2021-06-03 01:19:45,870 - __main__ - INFO - Training started from 1 iteration\n",
      "2021-06-03 01:20:55,643 - __main__ - INFO - StatisticCollector 0 add train_loss with value 0.05555022031784058\n",
      "2021-06-03 01:20:55,643 - __main__ - INFO - StatisticCollector 0 add train_loss with value 0.05555022031784058\n",
      "2021-06-03 01:20:55,668 - __main__ - INFO - StatisticCollector 0 add train_precision with value 36.02399826049805\n",
      "2021-06-03 01:20:55,668 - __main__ - INFO - StatisticCollector 0 add train_precision with value 36.02399826049805\n",
      "2021-06-03 01:20:55,670 - __main__ - INFO - StatisticCollector 0 add lr with value 0.07979539641943734\n",
      "2021-06-03 01:20:55,670 - __main__ - INFO - StatisticCollector 0 add lr with value 0.07979539641943734\n",
      "2021-06-03 01:20:55,694 - __main__ - INFO - StatisticCollector 1 add train_loss with value 0.055768300685882566\n",
      "2021-06-03 01:20:55,694 - __main__ - INFO - StatisticCollector 1 add train_loss with value 0.055768300685882566\n",
      "2021-06-03 01:20:55,696 - __main__ - INFO - StatisticCollector 1 add train_precision with value 34.93600082397461\n",
      "2021-06-03 01:20:55,696 - __main__ - INFO - StatisticCollector 1 add train_precision with value 34.93600082397461\n",
      "2021-06-03 01:20:55,697 - __main__ - INFO - StatisticCollector 1 add lr with value 0.07979539641943734\n",
      "2021-06-03 01:20:55,697 - __main__ - INFO - StatisticCollector 1 add lr with value 0.07979539641943734\n",
      "2021-06-03 01:20:55,722 - __main__ - INFO - StatisticCollector 2 add train_loss with value 0.05544127432823181\n",
      "2021-06-03 01:20:55,722 - __main__ - INFO - StatisticCollector 2 add train_loss with value 0.05544127432823181\n",
      "2021-06-03 01:20:55,723 - __main__ - INFO - StatisticCollector 2 add train_precision with value 35.768001556396484\n",
      "2021-06-03 01:20:55,723 - __main__ - INFO - StatisticCollector 2 add train_precision with value 35.768001556396484\n",
      "2021-06-03 01:20:55,725 - __main__ - INFO - StatisticCollector 2 add lr with value 0.07979539641943734\n",
      "2021-06-03 01:20:55,725 - __main__ - INFO - StatisticCollector 2 add lr with value 0.07979539641943734\n",
      "2021-06-03 01:20:55,749 - __main__ - INFO - StatisticCollector 3 add train_loss with value 0.05516212530136108\n",
      "2021-06-03 01:20:55,749 - __main__ - INFO - StatisticCollector 3 add train_loss with value 0.05516212530136108\n",
      "2021-06-03 01:20:55,751 - __main__ - INFO - StatisticCollector 3 add train_precision with value 36.183998107910156\n",
      "2021-06-03 01:20:55,751 - __main__ - INFO - StatisticCollector 3 add train_precision with value 36.183998107910156\n",
      "2021-06-03 01:20:55,752 - __main__ - INFO - StatisticCollector 3 add lr with value 0.07979539641943734\n",
      "2021-06-03 01:20:55,752 - __main__ - INFO - StatisticCollector 3 add lr with value 0.07979539641943734\n",
      "2021-06-03 01:20:55,776 - __main__ - INFO - Iteration: 391 / 391\n",
      "2021-06-03 01:20:55,776 - __main__ - INFO - Iteration: 391 / 391\n",
      "2021-06-03 01:20:59,189 - __main__ - INFO - StatisticCollector 0 add val_precision with value 31.700000762939453\n",
      "2021-06-03 01:20:59,189 - __main__ - INFO - StatisticCollector 0 add val_precision with value 31.700000762939453\n",
      "2021-06-03 01:20:59,191 - __main__ - INFO - StatisticCollector 0 add val_loss with value 187.38978791236877\n",
      "2021-06-03 01:20:59,191 - __main__ - INFO - StatisticCollector 0 add val_loss with value 187.38978791236877\n",
      "2021-06-03 01:21:02,647 - __main__ - INFO - StatisticCollector 1 add val_precision with value 31.81999969482422\n",
      "2021-06-03 01:21:02,647 - __main__ - INFO - StatisticCollector 1 add val_precision with value 31.81999969482422\n",
      "2021-06-03 01:21:02,650 - __main__ - INFO - StatisticCollector 1 add val_loss with value 185.04018652439117\n",
      "2021-06-03 01:21:02,650 - __main__ - INFO - StatisticCollector 1 add val_loss with value 185.04018652439117\n",
      "2021-06-03 01:21:06,081 - __main__ - INFO - StatisticCollector 2 add val_precision with value 32.5\n",
      "2021-06-03 01:21:06,081 - __main__ - INFO - StatisticCollector 2 add val_precision with value 32.5\n",
      "2021-06-03 01:21:06,084 - __main__ - INFO - StatisticCollector 2 add val_loss with value 177.14494860172272\n",
      "2021-06-03 01:21:06,084 - __main__ - INFO - StatisticCollector 2 add val_loss with value 177.14494860172272\n",
      "2021-06-03 01:21:09,555 - __main__ - INFO - StatisticCollector 3 add val_precision with value 31.31999969482422\n",
      "2021-06-03 01:21:09,555 - __main__ - INFO - StatisticCollector 3 add val_precision with value 31.31999969482422\n",
      "2021-06-03 01:21:09,558 - __main__ - INFO - StatisticCollector 3 add val_loss with value 191.5159842967987\n",
      "2021-06-03 01:21:09,558 - __main__ - INFO - StatisticCollector 3 add val_loss with value 191.5159842967987\n",
      "2021-06-03 01:21:09,595 - __main__ - INFO - StatisticCollector global_statistic add coef_of_var with value 0.048428989946842194\n",
      "2021-06-03 01:21:09,595 - __main__ - INFO - StatisticCollector global_statistic add coef_of_var with value 0.048428989946842194\n",
      "2021-06-03 01:21:09,609 - __main__ - INFO - StatisticCollector global_statistic add param_deviation_L1 with value {0: 48.553123, 1: 45.724945, 2: 48.483543, 3: 45.927925}\n",
      "2021-06-03 01:21:09,609 - __main__ - INFO - StatisticCollector global_statistic add param_deviation_L1 with value {0: 48.553123, 1: 45.724945, 2: 48.483543, 3: 45.927925}\n",
      "2021-06-03 01:21:09,614 - __main__ - INFO - StatisticCollector global_statistic add param_deviation_L2 with value {0: 0.15130006, 1: 0.14601158, 2: 0.15168037, 3: 0.15471868}\n",
      "2021-06-03 01:21:09,614 - __main__ - INFO - StatisticCollector global_statistic add param_deviation_L2 with value {0: 0.15130006, 1: 0.14601158, 2: 0.15168037, 3: 0.15471868}\n",
      "2021-06-03 01:21:09,618 - __main__ - INFO - StatisticCollector global_statistic add param_deviation_Linf with value {0: 0.009383738, 1: 0.009133369, 2: 0.010331005, 3: 0.009904377}\n",
      "2021-06-03 01:21:09,618 - __main__ - INFO - StatisticCollector global_statistic add param_deviation_Linf with value {0: 0.009383738, 1: 0.009133369, 2: 0.010331005, 3: 0.009904377}\n",
      "2021-06-03 01:21:09,633 - __main__ - INFO - StatisticCollector global_statistic add iterations_time with value 83.75762987136841\n",
      "2021-06-03 01:21:09,633 - __main__ - INFO - StatisticCollector global_statistic add iterations_time with value 83.75762987136841\n",
      "2021-06-03 01:21:09,638 - __main__ - INFO - Elapsed time : 0:01:31\n",
      "2021-06-03 01:21:09,638 - __main__ - INFO - Elapsed time : 0:01:31\n",
      "/home/sergey/anaconda3/envs/distrib-learning/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "2021-06-03 01:21:09,748 - __main__ - INFO - FINISH\n",
      "2021-06-03 01:21:09,748 - __main__ - INFO - FINISH\n"
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
